//! Custom Allocator based on buddy System
#![deny(missing_docs)]
#![cfg_attr(all(feature = "no-std", not(test)), no_std)]
#![feature(allocator_api)]
#![feature(strict_provenance)]
#![feature(stmt_expr_attributes)]
#![feature(slice_ptr_get)]
#![feature(const_align_offset)]
#![feature(const_mut_refs)]
#![feature(const_slice_index)]
#![feature(const_option)]
#![feature(const_convert)]
#![feature(const_trait_impl)]
#![feature(const_try)]
#![feature(const_num_from_num)]
#![feature(const_result_drop)]
#![feature(const_eval_limit)] // https://github.com/rust-lang/rust/issues/93481
#![const_eval_limit = "0"]

mod inner_allocator;
mod mutex;
#[cfg(test)]
mod tests;

use core::alloc::{AllocError, Allocator, GlobalAlloc, Layout};
use core::marker::PhantomData;
use core::ops::Deref;
#[cfg(feature = "no-std")]
use core::ptr::null_mut;
use core::ptr::NonNull;
#[cfg(not(feature = "no-std"))]
use std::alloc::handle_alloc_error;

/// These traits are exported to implement with your own Mutex
pub use mutex::RwMutex;

pub use inner_allocator::BuddyError;
pub use inner_allocator::{AddressSpaceRef, InnerBuddy, StaticAddressSpace};
pub use inner_allocator::{MAX_SUPPORTED_ALIGN, MIN_BUDDY_NB, MIN_CELL_LEN};

/// Buddy Allocator
#[repr(C, align(16))]
pub struct ClonableBuddy<
    'a,
    T: Deref<Target = ProtectedBuddy<'a, X, M>> + Send + Sync + Clone,
    X: RwMutex<InnerBuddy<'a, M>> + Send + Sync,
    const M: usize,
> {
    static_allocator: T,
    phantom: PhantomData<&'a X>,
}

impl<'a, T, X, const M: usize> ClonableBuddy<'a, T, X, M>
where
    T: Deref<Target = ProtectedBuddy<'a, X, M>> + Send + Sync + Clone,
    X: RwMutex<InnerBuddy<'a, M>> + Send + Sync,
{
    /// Create a new Buddy Allocator
    pub fn new(static_allocator: T) -> Self {
        Self {
            static_allocator,
            phantom: PhantomData,
        }
    }
    /// Allocate memory: should help for a global allocator implementation
    #[inline(always)]
    pub fn allocate(&self, layout: Layout) -> Result<NonNull<[u8]>, BuddyError> {
        self.static_allocator.allocate(layout)
    }
    /// Deallocate memory: should help for a global allocator implementation
    #[inline(always)]
    pub fn deallocate(&self, ptr: NonNull<u8>, layout: Layout) -> Result<(), BuddyError> {
        self.static_allocator.deallocate(ptr, layout)
    }
    /// TODO
    #[inline(always)]
    pub fn reserve(&self, index: usize, size: usize) -> Result<(), BuddyError> {
        self.static_allocator.reserve(index, size)
    }
    /// TODO
    #[inline(always)]
    pub fn unreserve(&self, index: usize) -> Result<(), BuddyError> {
        self.static_allocator.unreserve(index)
    }
}

/// Clone Boilerplate for ClonableBuddy<'a, T, X, M>... - Cannot Derive Naturaly
impl<'a, T, X, const M: usize> Clone for ClonableBuddy<'a, T, X, M>
where
    T: Deref<Target = ProtectedBuddy<'a, X, M>> + Send + Sync + Clone,
    X: RwMutex<InnerBuddy<'a, M>> + Send + Sync,
{
    fn clone(&self) -> Self {
        Self {
            static_allocator: self.static_allocator.clone(),
            phantom: PhantomData,
        }
    }
}

unsafe impl<'a, T, X, const M: usize> Allocator for ClonableBuddy<'a, T, X, M>
where
    T: Deref<Target = ProtectedBuddy<'a, X, M>> + Send + Sync + Clone,
    X: RwMutex<InnerBuddy<'a, M>> + Send + Sync,
{
    fn allocate(&self, layout: Layout) -> Result<NonNull<[u8]>, AllocError> {
        self.allocate(layout).map_err(|e| e.into())
    }
    unsafe fn deallocate(&self, ptr: NonNull<u8>, layout: Layout) {
        self.deallocate(ptr, layout).unwrap();
    }
}

/// Static Buddy Allocator
#[repr(C, align(16))]
pub struct ProtectedBuddy<'a, X, const M: usize>
where
    X: RwMutex<InnerBuddy<'a, M>>,
{
    data: X,
    error_hook: Option<fn(BuddyError) -> ()>,
    phantom: PhantomData<&'a X>,
}

impl<'a, X, const M: usize> ProtectedBuddy<'a, X, M>
where
    X: RwMutex<InnerBuddy<'a, M>>,
{
    /// Attach a previously allocated chunk generated by create_static_memory_area()
    pub const fn new(mutex_of_static_address_space: X, error_hook: Option<fn(BuddyError)>) -> Self {
        Self {
            data: mutex_of_static_address_space,
            error_hook,
            phantom: PhantomData,
        }
    }
    /// Allocate memory: should help for a global allocator implementation
    #[inline(always)]
    pub fn allocate(&self, layout: Layout) -> Result<NonNull<[u8]>, BuddyError> {
        self.data
            .lock_mut(|r| r.alloc(layout).map_err(|e| self.check(e)))
            .unwrap()
    }
    /// dellocate memory: should help for a global allocator implementation
    #[inline(always)]
    pub fn deallocate(&self, ptr: NonNull<u8>, layout: Layout) -> Result<(), BuddyError> {
        self.data
            .lock_mut(|r| r.dealloc(ptr, layout).map_err(|e| self.check(e)))
            .unwrap()
    }
    /// TODO
    #[inline(always)]
    pub fn reserve(&self, index: usize, size: usize) -> Result<(), BuddyError> {
        self.data
            .lock_mut(|r| r.reserve(index, size).map_err(|e| self.check(e)))
            .unwrap()
    }
    /// TODO
    #[inline(always)]
    pub fn unreserve(&self, index: usize) -> Result<(), BuddyError> {
        self.data
            .lock_mut(|r| r.unreserve(index).map_err(|e| self.check(e)))
            .unwrap()
    }
    #[inline(always)]
    fn check(&self, error: BuddyError) -> BuddyError {
        if let Some(error_hook) = self.error_hook {
            error_hook(error);
        }
        error
    }
}

unsafe impl<'a, X, const M: usize> Allocator for ProtectedBuddy<'a, X, M>
where
    X: RwMutex<InnerBuddy<'a, M>>,
{
    fn allocate(&self, layout: Layout) -> Result<NonNull<[u8]>, AllocError> {
        self.allocate(layout).map_err(|e| e.into())
    }
    unsafe fn deallocate(&self, ptr: NonNull<u8>, layout: Layout) {
        self.deallocate(ptr, layout).unwrap();
    }
}

unsafe impl<'a, X, const M: usize> GlobalAlloc for ProtectedBuddy<'a, X, M>
where
    X: RwMutex<InnerBuddy<'a, M>>,
{
    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {
        match self.allocate(layout) {
            Ok(non_null) => non_null.as_mut_ptr(),
            Err(_e) => {
                #[cfg(not(feature = "no-std"))]
                handle_alloc_error(layout);
                #[cfg(feature = "no-std")]
                null_mut()
            }
        }
    }
    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {
        self.deallocate(NonNull::new(ptr).unwrap(), layout).unwrap();
    }
}

#[allow(unused_variables)]
impl const From<BuddyError> for AllocError {
    #[inline(always)]
    fn from(error: BuddyError) -> Self {
        AllocError
    }
}

// TODO: design Realloc & Shrink
// TODO: Draw nodes to explain the Buddy research update tree
// TODO: Select location of buddy Metadata
// TODO: Create test of allowing more memory space to be addressable
// TODO: Reserve blocks
// TODO: Create good documentations

// /// Used only for debug purposes
// #[cfg(not(feature = "no-std"))]
// #[allow(dead_code)]
// fn debug(&self) {
//     self.data
//         .lock_mut(|refer| {
//             for (i, v) in refer.0.iter().enumerate() {
//                 print!("{:02x} ", v);
//                 if i != 0 && (i + 1) % 32 == 0 {
//                     println!();
//                 }
//             }
//             println!();
//         })
//         .unwrap();
// }

// #![cfg_attr(all(feature = "no-std", not(test)), feature(alloc_error_handler))]
// #[cfg(all(feature = "no-std", not(test)))]
// #[alloc_error_handler]
// fn out_of_memory(_: core::alloc::Layout) -> ! {
//      panic!("Sa mere");
// }
// ___ Testing on 64bits system Linux (with address sanitizer) ___
// RUST_BACKTRACE=1 RUSTFLAGS=-Zsanitizer=address cargo test -Zbuild-std --target x86_64-unknown-linux-gnu
// ___ Testing on 32bits system Linux (address sanitizer is unaivalable for this arch) ___
// RUST_BACKTRACE=1 cargo test --target i686-unknown-linux-gnu
